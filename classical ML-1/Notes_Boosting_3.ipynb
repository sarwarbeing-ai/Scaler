{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- **GBDT**\n",
        "    - Impact of outliers\n",
        "    - Feature importance\n",
        "\n",
        "- **XGBoost**\n",
        "    - Hyperparams\n",
        "    - Code walkthrough\n",
        "\n",
        "- **LightGBM**\n",
        "    - GOSS (Gradient based one side sampling)\n",
        "    - Exclusive Feature Bundling\n",
        "    - Code walkthrough\n",
        "\n",
        "- **Cascading**\n",
        "\n",
        "- **Stacking**\n",
        "\n",
        "- **Comparison**\n",
        "    - RF vs GBDT\n",
        "    - Cascading vs Stacking"
      ],
      "metadata": {
        "id": "ZJgl0oswKFFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "!gdown 171Yoe_GSapyrmOnD9oBzHWNOD_OnQs0F\n",
        "!gdown 1hnIlTPW3AMeB69EbeaXCRIrpMVT1Vwmc\n",
        "!gdown 1nZtB_RtxMg_MgoRczb8UWQX-AEK_l3qE\n",
        "!gdown 1zLDUErwKdmF-RacOyHEuI_z_46LssQtP\n",
        "\n",
        "\n",
        "with open('X_train.pickle', 'rb') as handle:\n",
        "    X_train = pickle.load(handle)\n",
        "\n",
        "with open('X_test.pickle', 'rb') as handle:\n",
        "    X_test = pickle.load(handle)\n",
        "\n",
        "with open('Y_train.pickle', 'rb') as handle:\n",
        "    Y_train = pickle.load(handle)\n",
        "\n",
        "with open('Y_test.pickle', 'rb') as handle:\n",
        "    Y_test = pickle.load(handle)"
      ],
      "metadata": {
        "id": "qyP1YPhBKhEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a0d88a-d57e-4bce-e122-1ee1ca49714c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=171Yoe_GSapyrmOnD9oBzHWNOD_OnQs0F\n",
            "To: /content/Y_test.pickle\n",
            "100% 31.7k/31.7k [00:00<00:00, 37.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hnIlTPW3AMeB69EbeaXCRIrpMVT1Vwmc\n",
            "To: /content/X_test.pickle\n",
            "100% 253k/253k [00:00<00:00, 86.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nZtB_RtxMg_MgoRczb8UWQX-AEK_l3qE\n",
            "To: /content/Y_train.pickle\n",
            "100% 126k/126k [00:00<00:00, 85.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zLDUErwKdmF-RacOyHEuI_z_46LssQtP\n",
            "To: /content/X_train.pickle\n",
            "100% 1.01M/1.01M [00:00<00:00, 103MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.tree import DecisionTreeClassifier as DTC\n",
        "# from sklearn import tree\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# import datetime as dt\n",
        "# from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "9cYClyNJKn7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBqvnZRr0k1s"
      },
      "source": [
        "# **Impact of outliers** \n",
        "\n",
        "#### Question: Will outliers impact GBDT?\n",
        "\n",
        "Outliers can impact GBDT\n",
        "\n",
        "- Each model is fit on the residual of the previous model\n",
        "- Outliers will have higher residual values\n",
        "- So, so gradient boosting will focus a large amount of its attention on reducing residual for these points.\n",
        "\n",
        "#### Question: How to handle outliers?\n",
        "1. Remove outliers\n",
        "2. Specialized loss functions to handle outliers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow9M5e0tY3MC"
      },
      "source": [
        "Let us consider squared-loss which is $∑_{i=1}^n(y_i - ŷ_i)^2$\n",
        "\n",
        "Here, if there is an outlier the error increases quadratically because of squaring\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7kIv4VAcP4y"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1eWKV9YbLFQYGQCuSR_FGHANPDw68L84D' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KViQydjca86"
      },
      "source": [
        "\n",
        "##### What changes can we make in the loss function so that the model be robust to outliers?\n",
        "\n",
        "* We can use **Root mean squared error**\n",
        "* We can use absolute values of the error \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuawTwrpeY0r"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1QrUznldwhmGMthsMG-mmuz7L89zXS9FC' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzNXtSwgHYeX"
      },
      "source": [
        "#### Question: abs function is not differentiable at 0; how to handle that?\n",
        "   * As, already the error is 0, we simply use derivative of abs function @0 = 0 (computational hack)\n",
        "\n",
        "Huber loss can also be used.\n",
        " * This function be quadratic in some areas and linear in some\n",
        "   * As mentioned in the formuala, it uses the quadratic function in some range and liinear in the other range of values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krsWIaONee2V"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1ryIZnNANcX_a2nQjeWvwibEaoQz1CMOn' >\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvplWXmGenbb"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1-fA_MyJbXQbwq1yBygn0109CljpZD0VZ' >\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wat_HfJdHjCb"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1menZJ9cL_62wkbz-zD8W4uFbFJY5GgRk' >\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhx6tu0Fs1vD"
      },
      "source": [
        "# **Feature Importance**\n",
        "\n",
        "#### How do we find feature importance in GBDT ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkgJx7ePwgHS"
      },
      "source": [
        "We simply find the feature importance of feature in each tree and \n",
        "- then take the average of these values to get over-all feature importance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoHHWmNvxGXL"
      },
      "source": [
        "\n",
        "<img src='https://drive.google.com/uc?id=1NW-6jIIU55duZGJGzEIUk5P-8QZ3DZ-m' width = 600 >\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHbO_74uyf3p"
      },
      "source": [
        "#### Code walkthrough"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "0X4fO0ZRLDKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b1KA2MqkKj3",
        "outputId": "f0487767-77f9-49f1-ef84-fd8d7cc1e411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.9950            7.54m\n",
            "         2           0.7782            6.24m\n",
            "         3           0.6374            5.37m\n",
            "         4           0.5332            4.93m\n",
            "         5           0.4521            5.56m\n",
            "         6           0.3916            5.57m\n",
            "         7           0.3454            5.61m\n",
            "         8           0.3093            5.74m\n",
            "         9           0.2782            5.85m\n",
            "        10           0.2546            5.58m\n",
            "        20           0.1377            4.33m\n",
            "        30           0.0919            3.67m\n",
            "        40           0.0664            3.25m\n",
            "        50           0.0502            2.89m\n",
            "        60           0.0382            2.55m\n",
            "        70           0.0305            2.25m\n",
            "        80           0.0243            1.96m\n",
            "        90           0.0194            1.65m\n",
            "       100           0.0157            1.35m\n",
            "Time taken for training : 0:03:48.389666\n",
            "Training accuracy:1.0\n",
            "Test Accuracy: 0.9617042860765914\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "\n",
        "start = dt.datetime.now()\n",
        "model3 = GBC(n_estimators=150, learning_rate=0.2, max_depth=4, random_state=0, verbose = 1).fit(X_train, Y_train)\n",
        "end = dt.datetime.now()\n",
        "\n",
        "print(f\"Time taken for training : {end - start}\\nTraining accuracy:{model3.score(X_train, Y_train)}\\nTest Accuracy: {model3.score(X_test, Y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuQ_R554x4HC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "3522d07f-fb2e-419a-af03-b70b771af106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.14900177 0.08996997 0.10690476 0.16619893 0.17604845 0.12061436\n",
            " 0.0787365  0.11252526]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(model3.feature_importances_)\n",
        "\n",
        "plt.bar(range(len(model3.feature_importances_)), model3.feature_importances_)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnrIE_4-kfIM"
      },
      "source": [
        "Notice,\n",
        "- It took around 4 min to train a single model\n",
        "- Imagine how much time it'll take if we do hyperparam tuning on it.\n",
        "\n",
        "Sklearn's implemenation of GBDT is not optimized and hence not preferred.\n",
        "\n",
        "**So, what library do we use then?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pe4czVs1kVS"
      },
      "source": [
        "# **Xgboost**\n",
        "\n",
        "XGBoost is one the popular library known for its well optimized code\n",
        "\n",
        "For example : \n",
        "\n",
        "- if you have numerical feature $f_i$, \n",
        "    - instead of tryinig all the values for thresholding, \n",
        "    - it build a histogram of data and use simple rules like quartiles and percentiles to make thresholding.\n",
        "\n",
        "- It also does multi core optimization (parallelization)\n",
        "    - it'll compute each branch of a base learner on different core to speed up the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGdVVzudUx0K"
      },
      "source": [
        "### **Xgboost hyperparams**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHwaJ4RCU2HS"
      },
      "source": [
        "1. **Eta**: or the learning rate is the shrinking/regularization term which we studier earlier \n",
        "\n",
        "2. **min_split_loss** specify the minimum Information Gain which you want for further split. \n",
        "\n",
        "#### Question: What happens if min_split_loss increases?\n",
        "If the min_split_loss value of the model is increased, \n",
        "- the splitting stops if the min_split_loss is not met. \n",
        "    \n",
        "Due to this the depth decreases resulting in shallow tress.\n",
        "\n",
        "Hence,results in the underfitting of the model.\n",
        "\n",
        "\n",
        "3. **max_depth**, this parameter is used to set the depth of the base learners  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShdCyR2XCbt"
      },
      "source": [
        "4. **min_child_weight**: you can increase the weight of the child due to which the splitting stops if the required threshold is not met"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X8kzQ0UX8-7"
      },
      "source": [
        "5. **subsample**. it's nothing but the row sampling \n",
        " * There are many ways of sampling, same with column sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0n-UauKYoym"
      },
      "source": [
        "6. **Lambda**, it is the used apply the L2 regularization on the weights, which is $γ$ in our case \n",
        "\n",
        "7. **Tree_methods**, there are many ways to build a tree, we can specify the method basing on the conditions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckHd2kWIXFH0"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1tvyj1KYedvVhaeIJIAh_ZillGmf5p5rE' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjHHBAPwXizX"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1k_JD_dg0las0-N03UWQ_jSzkIP1M-b9W' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUoUNjITZFFv"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Vvz_rxFrx0EAgwClXn8OFwkhZ_5eD9C0' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2S8tbitZzTU"
      },
      "source": [
        "#### What are most used hyperparams?\n",
        "\n",
        "- Number of estimators (M)\n",
        "- Depth\n",
        "- ν : learning rate\n",
        "- Col sampling/ row sampling \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qGNJ2_pacN7"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1n0JuWHd8NerqKnYnWFQqIwKeNuJG7PUr' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvsDq-PSfS29"
      },
      "source": [
        "### Code walkthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiwuBmp0fUqI"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "params = {\n",
        "        'learning_rate': [0.1, 0.5, 0.8],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5]\n",
        "        }\n",
        "xgb = XGBClassifier(n_estimators=100, objective='multi:softmax', num_class=20, silent=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isosAJtbfZr7"
      },
      "outputs": [],
      "source": [
        "folds = 3\n",
        "\n",
        "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
        "\n",
        "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=10, scoring='accuracy', n_jobs=4, cv=skf.split(X_train,Y_train), verbose=3, random_state=1001 )\n",
        "\n",
        "\n",
        "start = dt.datetime.now()\n",
        "random_search.fit(X_train, Y_train)\n",
        "end = dt.datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxwNTFHdfiJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19dde868-f700-4e51-e2c3-85a467e52187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best hyperparameters:\n",
            "{'subsample': 0.8, 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 1.0}\n"
          ]
        }
      ],
      "source": [
        "print('\\n Best hyperparameters:')\n",
        "print(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF4equbhfnZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbb567d-f4ee-4111-9565-8ab515708386"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=1.0, learning_rate=0.5, max_depth=5,\n",
              "              num_class=20, objective='multi:softprob', silent=True,\n",
              "              subsample=0.8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "best_xgb = XGBClassifier(n_estimators=100, objective='multi:softmax', num_class=20, subsample=0.8, max_depth=5, learning_rate=0.5, colsample_bytree=1.0, silent=True)\n",
        "best_xgb.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyAGwdadfsr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37fbd19-77cd-4a0f-abc6-ecec4dfa1753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for training : 0:04:44.867116\n",
            "Training accuracy:1.0\n",
            "Test Accuracy: 0.9786964240426071\n"
          ]
        }
      ],
      "source": [
        "print(f\"Time taken for training : {end - start}\\nTraining accuracy:{best_xgb.score(X_train, Y_train)}\\nTest Accuracy: {best_xgb.score(X_test, Y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFPM3x6NlX-7"
      },
      "source": [
        "Since we are using randomized Search\n",
        "- we made total of 30 fits \n",
        "    - total 10 combination of hyperparam\n",
        "    - 3 fold cv for each combination\n",
        "\n",
        "All these 30 fits took mere 5 mins to run compared to 4 mins for single fit of sklearn GBDT.\n",
        "\n",
        "**Do you now see how fast it is compared to sklearn implementation?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyAhXx1cytvk"
      },
      "source": [
        "#### Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2v-sFCtyvXe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "43216ab6-8928-437b-97f4-f9de76d41c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.14220932 0.06247859 0.1474603  0.13250431 0.21800207 0.12647994\n",
            " 0.07299956 0.09786595]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOKUlEQVR4nO3df6zddX3H8efLVnTTiSg3i6HMW2dn1v2ImGvJ4kbMECzBUP+ArCwuuJiwJbJoyLLULYGs/oMu2fyHbRLpwpxaEWbSjG6MDNyPLGhvEXUFO69dlTZuXCnTMR2s8t4f51s8nl28X+6Pfk8/PB/JDed8f9zzvg153m+/3/M9TVUhSWrXC4YeQJK0vgy9JDXO0EtS4wy9JDXO0EtS4zYOPcCkc889t2ZnZ4ceQ5LOKAcPHvxmVc0stW7qQj87O8v8/PzQY0jSGSXJ155tnaduJKlxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxU3dnrHQmmd1112CvffSmywd7bZ1ZPKKXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMb1Cn2S7UkOJ1lIsmuJ9dcneSjJF5P8XZJXj627JslXuq9r1nJ4SdLylg19kg3AzcBlwFbg6iRbJzb7PDBXVT8P3AF8sNv3FcCNwIXANuDGJOes3fiSpOX0OaLfBixU1ZGqegrYC+wY36Cq7quq73RP7wc2dY/fCtxTVSeq6nHgHmD72owuSeqjT+jPAx4Ze36sW/Zs3gX89XPZN8m1SeaTzC8uLvYYSZLU15pejE3yDmAO+IPnsl9V3VJVc1U1NzMzs5YjSdLzXp/QHwfOH3u+qVv2A5K8Bfg94IqqevK57CtJWj99Qn8A2JJkc5KzgJ3AvvENklwAfJhR5B8dW3U3cGmSc7qLsJd2yyRJp8my/zh4VZ1Mch2jQG8A9lTVoSS7gfmq2sfoVM1LgU8lAfh6VV1RVSeSvJ/RLwuA3VV1Yl1+EknSkpYNPUBV7Qf2Tyy7YezxW37IvnuAPSsdUJK0Ot4ZK0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1LheoU+yPcnhJAtJdi2x/qIkDyQ5meTKiXXfS/Jg97VvrQaXJPWzcbkNkmwAbgYuAY4BB5Lsq6qHxjb7OvBO4LeX+BbfrarXr8GskqQVWDb0wDZgoaqOACTZC+wAngl9VR3t1j29DjNKklahz6mb84BHxp4f65b19eIk80nuT/L2pTZIcm23zfzi4uJz+NaSpOWcjouxr66qOeBXgQ8l+cnJDarqlqqaq6q5mZmZ0zCSJD1/9An9ceD8seebumW9VNXx7r9HgM8AFzyH+SRJq9TnHP0BYEuSzYwCv5PR0fmykpwDfKeqnkxyLvAm4IMrHVbrZ3bXXYO99tGbLh/staXng2WP6KvqJHAdcDfwMHB7VR1KsjvJFQBJ3pjkGHAV8OEkh7rdfxqYT/IF4D7gpol360iS1lmfI3qqaj+wf2LZDWOPDzA6pTO53z8DP7fKGSVJq+CdsZLUOEMvSY3rdermTOJFRUn6QR7RS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNa65G6bUHm+Ck1bHI3pJapyhl6TGGXpJapyhl6TGGXpJapzvupEa5buVdIpH9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUuF6hT7I9yeEkC0l2LbH+oiQPJDmZ5MqJddck+Ur3dc1aDS5J6mfZ0CfZANwMXAZsBa5OsnVis68D7wQ+PrHvK4AbgQuBbcCNSc5Z/diSpL76HNFvAxaq6khVPQXsBXaMb1BVR6vqi8DTE/u+Fbinqk5U1ePAPcD2NZhbktRTn9CfBzwy9vxYt6yPXvsmuTbJfJL5xcXFnt9aktTHVFyMrapbqmququZmZmaGHkeSmrKxxzbHgfPHnm/qlvVxHHjzxL6f6bmvJJ12s7vuGuy1j950+bp83z5H9AeALUk2JzkL2Ans6/n97wYuTXJOdxH20m6ZJOk0WTb0VXUSuI5RoB8Gbq+qQ0l2J7kCIMkbkxwDrgI+nORQt+8J4P2MflkcAHZ3yyRJp0mfUzdU1X5g/8SyG8YeH2B0WmapffcAe1YxoyRpFabiYqwkaf0YeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMb1+jdjJWktze66a7DXPnrT5YO99lA8opekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxnln7Gnk3YCShuARvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuN6hT7J9iSHkywk2bXE+hcl+WS3/rNJZrvls0m+m+TB7utP13Z8SdJylr0zNskG4GbgEuAYcCDJvqp6aGyzdwGPV9Vrk+wEPgD8Srfuq1X1+jWeW5LUU58j+m3AQlUdqaqngL3AjoltdgC3dY/vAC5OkrUbU5K0Un1Cfx7wyNjzY92yJbepqpPAt4BXdus2J/l8kr9P8ktLvUCSa5PMJ5lfXFx8Tj+AJOmHW++Lsd8AfqKqLgCuBz6e5GWTG1XVLVU1V1VzMzMz6zySJD2/9An9ceD8seebumVLbpNkI3A28FhVPVlVjwFU1UHgq8BPrXZoSVJ/fUJ/ANiSZHOSs4CdwL6JbfYB13SPrwTurapKMtNdzCXJa4AtwJG1GV2S1Mey77qpqpNJrgPuBjYAe6rqUJLdwHxV7QNuBT6aZAE4weiXAcBFwO4k/ws8DfxmVZ1Yjx9EkrS0Xv/wSFXtB/ZPLLth7PH/AFctsd+dwJ2rnFGStAreGStJjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjesV+iTbkxxOspBk1xLrX5Tkk936zyaZHVv3vm754SRvXbvRJUl9LBv6JBuAm4HLgK3A1Um2Tmz2LuDxqnot8EfAB7p9twI7gZ8BtgN/3H0/SdJp0ueIfhuwUFVHquopYC+wY2KbHcBt3eM7gIuTpFu+t6qerKp/Axa67ydJOk029tjmPOCRsefHgAufbZuqOpnkW8Aru+X3T+x73uQLJLkWuLZ7+kSSw72mX3vnAt9c6c75wBpO8v8528o428o428oMOdurn21Fn9Cvu6q6Bbhl6DmSzFfV3NBzLMXZVsbZVsbZVmZaZ+tz6uY4cP7Y803dsiW3SbIROBt4rOe+kqR11Cf0B4AtSTYnOYvRxdV9E9vsA67pHl8J3FtV1S3f2b0rZzOwBfjc2owuSepj2VM33Tn364C7gQ3Anqo6lGQ3MF9V+4BbgY8mWQBOMPplQLfd7cBDwEng3VX1vXX6WdbC4KePfghnWxlnWxlnW5mpnC2jA29JUqu8M1aSGmfoJalxhr6z3Mc8DCXJniSPJvmXoWeZlOT8JPcleSjJoSTvGXqmU5K8OMnnknyhm+33h55pUpINST6f5K+GnmVckqNJvpTkwSTzQ88zLsnLk9yR5MtJHk7yC0PPBJDkdd2f16mvbyd579BzneI5ep75mId/BS5hdFPXAeDqqnpo0MGAJBcBTwB/XlU/O/Q845K8CnhVVT2Q5MeAg8Dbp+TPLcBLquqJJC8E/gl4T1Xdv8yup02S64E54GVV9bah5zklyVFgrqpWfOPPeklyG/CPVfWR7l2AP1pV/zn0XOO6nhwHLqyqrw09D3hEf0qfj3kYRFX9A6N3Mk2dqvpGVT3QPf4v4GGWuPN5CDXyRPf0hd3X1BzVJNkEXA58ZOhZzhRJzgYuYvQuP6rqqWmLfOdi4KvTEnkw9Kcs9TEPUxGsM0X3iaUXAJ8ddpLv606NPAg8CtxTVVMzG/Ah4HeAp4ceZAkF/G2Sg93Hk0yLzcAi8GfdKa+PJHnJ0EMtYSfwiaGHGGfotWpJXgrcCby3qr499DynVNX3qur1jO7I3pZkKk59JXkb8GhVHRx6lmfxi1X1BkafWPvu7vThNNgIvAH4k6q6APhvYGqupwF0p5OuAD419CzjDP2IH9WwQt357zuBj1XVXw49z1K6v97fx+ijsqfBm4ArunPhe4FfTvIXw470fVV1vPvvo8CnmZ5PnD0GHBv7m9kdjMI/TS4DHqiq/xh6kHGGfqTPxzxoQnfB81bg4ar6w6HnGZdkJsnLu8c/wuhC+5eHnWqkqt5XVZuqapbR/2v3VtU7Bh4LgCQv6S6s050WuRSYind8VdW/A48keV236GJGd91Pk6uZstM2MCWfXjm0Z/uYh4HHAiDJJ4A3A+cmOQbcWFW3DjvVM94E/Brwpe5cOMDvVtX+AWc65VXAbd07IF4A3F5VU/U2xin148CnR7/D2Qh8vKr+ZtiRfsBvAR/rDsiOAL8+8DzP6H4xXgL8xtCzTPLtlZLUOE/dSFLjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1Lj/g8dyr8ki9Rf/QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(best_xgb.feature_importances_)\n",
        "\n",
        "plt.bar(range(len(best_xgb.feature_importances_)), best_xgb.feature_importances_)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8YrMxzKbUt-"
      },
      "source": [
        "# **LightGBM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgmf4KdlbYOs"
      },
      "source": [
        "It was built at microsoft, primarily for a faster GBDT$.$\n",
        "\n",
        "It is typically faster than Xgboost because of the code optimization\n",
        "\n",
        "\n",
        "There are two main strategies for optimization:\n",
        "\n",
        "#### 1.  GOSS - Gradient based one side sampling\n",
        "\n",
        "When we are building the $m^{th}$ model the points we have is ($ x_i,res_{i,m} $),\n",
        "\n",
        "\n",
        "so here instead of considering all points \n",
        "\n",
        "- we drop the points in which the $res_{i,m}$ is small \n",
        "- i.e. smart sampling ( probability of getting large residual value is higher)\n",
        "\n",
        "So, when we are building $m^{th}$ model, we'll have fewer rows.\n",
        "\n",
        "Here the key is to reduce the number of data points due to which the model becomes faster\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj6dmciC2nX1"
      },
      "source": [
        "\n",
        "\n",
        " <img src='https://drive.google.com/uc?id=1NGKKYLSyz8MzFKQtzxnh9PTUbGQoM9JP' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp4giSc32mYW"
      },
      "source": [
        "#### 2.  Exclusive Feature Bundling (EFB)\n",
        "\n",
        "Let us assume we have a categorical feature with 3 categories \n",
        "- if we do **one hot encoding** (worst thing to do), \n",
        "    - for each row, only one of them will always be set i.e 1. \n",
        "\n",
        "<br>\n",
        "\n",
        "#### What does Exclusive feature bundling do ? (intuition not detailed)\n",
        "\n",
        "- It looks at all the dimensions \n",
        "- tries finding feature pairs s.t they are exclusive\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What does exclusive mean? \n",
        "Say we have feature $f_1$, $f_2$.\n",
        "\n",
        "When we say $f_1, f_2$ are exclusive, we mean\n",
        "- if value of $f_1$ occurs, $f_2$ value doesn't\n",
        "- or if $f_1$ is high, then $f_2$ is low\n",
        "\n",
        "<br>\n",
        "\n",
        "It tries to find these exclusive features (using graph based algo) and\n",
        "- group these features \n",
        "   \n",
        "So, here the key objective of EFB is to reduce the number of features and hence reduce dimensionality "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEXawqZG3KFk"
      },
      "source": [
        " <img src='https://drive.google.com/uc?id=1G2Ilv5_nhQ0rrX0KUp60v9UoqlDApWl4' >\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLwihWKT6h3f"
      },
      "source": [
        "### Code walkthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lhDWx2x6f2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e7d8d9-d430-4ce4-e024-0ed095fc228e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "#Refer: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "import datetime as dt\n",
        "gridParams = {\n",
        "    'learning_rate': [0.1, 0.5, 0.8],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['multiclass'],\n",
        "    'max_depth' : [5,6,7,8],\n",
        "    'colsample_bytree' : [0.5,0.7],\n",
        "    'subsample' : [0.5,0.7],\n",
        "    'metric':['multi_error'],\n",
        "    'random_state' : [501]\n",
        "    }\n",
        "\n",
        "clf = lgb.LGBMClassifier(num_classes=20)\n",
        "grid = RandomizedSearchCV(clf,gridParams,verbose=3,cv=3,n_jobs = -1,n_iter=10,)\n",
        "\n",
        "start = dt.datetime.now()\n",
        "grid.fit(X_train,Y_train)\n",
        "end = dt.datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85LuLTURDIDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0c9b43-fb2e-4b69-df5f-de158121ab44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'subsample': 0.5,\n",
              " 'random_state': 501,\n",
              " 'objective': 'multiclass',\n",
              " 'metric': 'multi_error',\n",
              " 'max_depth': 7,\n",
              " 'learning_rate': 0.5,\n",
              " 'colsample_bytree': 0.7,\n",
              " 'boosting_type': 'gbdt'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJJzPDtgqXoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48215b6-8595-40e8-a4a7-a9463b443078"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_typ='gbdt', colsample_bytree=0.7, learning_rate=0.5,\n",
              "               max_depth=8, num_class=20, objective='multiclass',\n",
              "               random_state=501, subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "best_lgbm = lgb.LGBMClassifier(boosting_typ = 'gbdt',\n",
        "                              objective = 'multiclass',\n",
        "                              num_class=20, \n",
        "                              colsample_bytree=0.7, \n",
        "                              subsample=0.7, \n",
        "                              max_depth=8, \n",
        "                              learning_rate=0.5, \n",
        "                              random_state = 501)\n",
        "best_lgbm.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NStOIh5osWOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1374be0-9372-4744-be47-42bf531c2544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for training : 0:01:06.067424\n",
            "Training accuracy:1.0\n",
            "Test Accuracy: 0.9857976160284048\n"
          ]
        }
      ],
      "source": [
        "print(f\"Time taken for training : {end - start}\\nTraining accuracy:{best_lgbm.score(X_train, Y_train)}\\nTest Accuracy: {best_lgbm.score(X_test, Y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kEbLJjO4qUz"
      },
      "source": [
        "Notice the time it took for 30 fits in XGBoost(5 mins) vs LightGBM (2 mins)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tAu9F1rvmvE"
      },
      "source": [
        "# **Cascading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0QwDhMlvpQI"
      },
      "source": [
        "Lets, assume we are to detect a fraudulent transaction or not \n",
        " \n",
        "Let the dataset be $D_1$ which will be imbalanced, and \n",
        "\n",
        "- $y=1$ for fraudulent transaction\n",
        "- $y =0$ for non fraudulent transaction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i14u9uSDCg9C"
      },
      "source": [
        "For a query point $x_q$, \n",
        "- we will pass this point through the first model $M_1$\n",
        "- Model $M_1$ will return the probability of the query point being a fraud\n",
        "\n",
        "\n",
        "Based on probability, we'll split it in 2 parts:\n",
        "- if the probability of $y$ being 1 is extremely low, say $< 0.001$ then \n",
        "    - we consider that as not fraudulent, let this data be $D_1'$.\n",
        "\n",
        "#### What happens to rest of the data? \n",
        "\n",
        "The rest of the points ($D_1-D_1'$) i.e. data with prob. > 0.001 which we are not sure about \n",
        "- will be passed through the next model $M_2$ \n",
        "- Model $M_2$ will be more stricter i.e. it'll penalize more.\n",
        "\n",
        "Again model $M_2$ will split into 2 parts\n",
        "- non fraud (say, $P(y =1 | x_q) < 0.001$)\n",
        "- fraud transac. (p > 0.001)\n",
        "\n",
        "We can again add another model after $M_2$ which will work on same principles\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfzVddDyS_N_"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1TwfqSCDjjS3MsXaBadxNBIvBfF9LQ0JC' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q98Cc_gUP_Vt"
      },
      "source": [
        "#### Did you notice the structure of model? \n",
        "We are cascading one model after another.\n",
        "\n",
        "In the first model we are just removing all the genuine customers\n",
        "- in second model, we are trying to find the may be fraudalent points from 2nd data set, \n",
        "\n",
        "we contimue doing this **cascading**\n",
        "\n",
        "Every model is trained on different datasets ($D_n - D_n^1$ )\n",
        "\n",
        "If even after all these models, we are not sure there will be a human at last to verify the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv0_VBKNTGS6"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=16cjT66tLCnFRuGzGPVmw4KUOgz0k85Ot' >\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvzpMEk4Uijn"
      },
      "source": [
        "# **Stacking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnAvHOerUlbj"
      },
      "source": [
        "Lets assume we have a data set of $n$ poits.\n",
        "\n",
        "#### What do we do in stacking?\n",
        "We train $m$ **individual** models (base learners) on this data set, \n",
        "- these models can be different types of models like Decision tree,  GBDT, Random forest etc.\n",
        "\n",
        "Do note that, these m model can be  optimial models.\n",
        "- i.e. perfectly fitted model with minimum CV error.\n",
        " \n",
        "Let these base learners be $c_1,c_2,....c_n$\n",
        "* Now, given a datapoint, each of these model will give a prediction ($p_1,p_2,...p_n$) \n",
        "\n",
        "Unlike RF, we we train m model and aggregate the prediction using mean/median (regression) or majority vote (classification),\n",
        "\n",
        "**In Stacking, We build a meta classifer on the predictios of the base learners**\n",
        "\n",
        "#### What model will we use as Meta classifier? \n",
        "The Meta-classifier can be any model\n",
        "* And this Meta-classifier gives the final output of the data \n",
        "\n",
        "#### What is happening in Stacking intuitively?\n",
        "Here, we are taking the outputs of the perfectly build models and stacking them together to train a Meta-classifier to get the final output\n",
        "\n",
        "BAM!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJhyoBHtWo7x"
      },
      "source": [
        " \n",
        "\n",
        "<img src='https://drive.google.com/uc?id=14Ishp1beh9iHH1TrOICRomMKRMpgRrLQ' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO7oEQ8WTFRP"
      },
      "source": [
        "#### How is this implemented ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFNQokQaYQwn"
      },
      "source": [
        "This is implemented using the **StackingClassifier** library from **miextend.classifier** module\n",
        "* In the code we import all the libraries first\n",
        "* Then **create the base classfiers** and pass these as **inputs to stacking classfier** and use **set any model as Meta-Classifier.**\n",
        "* Now, **we train the model** and it's done\n",
        "\n",
        "Double BAM!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmaRZzoaHgU"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=17wgLrV5LKmISQw7kzLrW2rzuDiolFDM5' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA71V5rNTYtG"
      },
      "source": [
        "#### Idea looks interesting, Why don't we use them ?\n",
        "Ans: coz Deep learning came into existence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOWVKk16NcHG"
      },
      "source": [
        "## Comparison\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK4BNa4YOOAU"
      },
      "source": [
        "### RF vs GBDT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT2hx1lhPBp8"
      },
      "source": [
        "We use GBDT more often than RF\n",
        "\n",
        "#### Question: Why GBDT is used more often than RF?\n",
        "\n",
        "1. Because we can choose any differentiable loss function but we cannot do this for random forest \n",
        "2. Though training time varies but it's only done once so it doesnt matter much, but Run-time is important as queries are given everytime\n",
        "3. GBDT  has cheaper Run-time because \n",
        "    - the base learners are shallow and \n",
        "    - Random forest has deeper trees and \n",
        "    - the number of trees to train in GBDT are less when compared to Random Forest  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyZ70zf4R1kI"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1kBqeWQ-y71bi6ndWQPUn58IGo4FmiTjT' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Lgo3AbNfsI"
      },
      "source": [
        "# **Cascading vs Stacking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbMPNBo2m87I"
      },
      "source": [
        "\n",
        "**Cascading** is used when the risk or cost of mistakes is high, and the data is highly imbalanced.\n",
        " * Like fraud transaction detection in amazon\n",
        "\n",
        "#### What about the explainability of the model?\n",
        "We make sure thst every model is explainable, so that we can explain the output using these models \n",
        "  * We will see few algorithms, like **LIME and SHAP** which can explain any black box algorithm after few lectures in Deep Learning.\n",
        "\n",
        "\n",
        "\n",
        "**Stacking** is mostly seen in kaggle competitions, not so much in real world."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjz5HMFAoE0b"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1kzRryuOAFc5_HYtWcHxSGDwml-dHtGQk' >\n"
      ]
    }
  ]
}